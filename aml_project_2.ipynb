{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### artificial_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>477</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>463</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>487</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>488</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  490  491  492  493   \n",
       "0  485  477  537  479  452  471  491  476  475  473  ...  477  481  477  485  \\\n",
       "1  483  458  460  487  587  475  526  479  485  469  ...  463  478  487  338   \n",
       "2  487  542  499  468  448  471  442  478  480  477  ...  487  481  492  650   \n",
       "3  480  491  510  485  495  472  417  474  502  476  ...  491  480  474  572   \n",
       "4  484  502  528  489  466  481  402  478  487  468  ...  488  479  452  435   \n",
       "\n",
       "   494  495  496  497  498  499  \n",
       "0  511  485  481  479  475  496  \n",
       "1  513  486  483  492  510  517  \n",
       "2  506  501  480  489  499  498  \n",
       "3  454  469  475  482  494  461  \n",
       "4  486  508  481  504  495  511  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artificial_train_x = pd.read_csv(\"datasets/artificial_train.data\", sep = \" \", header=None).iloc[:, 0:500]\n",
    "artificial_train_x.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### artificial_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artificial_train_y = pd.read_csv(\"datasets/artificial_train.labels\", sep = \" \", header=None).iloc[:, 0]\n",
    "artificial_train_y[artificial_train_y == -1] = 0\n",
    "artificial_train_y.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### artificial_valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>483</td>\n",
       "      <td>454</td>\n",
       "      <td>513</td>\n",
       "      <td>495</td>\n",
       "      <td>523</td>\n",
       "      <td>469</td>\n",
       "      <td>453</td>\n",
       "      <td>477</td>\n",
       "      <td>506</td>\n",
       "      <td>479</td>\n",
       "      <td>...</td>\n",
       "      <td>455</td>\n",
       "      <td>480</td>\n",
       "      <td>543</td>\n",
       "      <td>259</td>\n",
       "      <td>413</td>\n",
       "      <td>520</td>\n",
       "      <td>485</td>\n",
       "      <td>498</td>\n",
       "      <td>523</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>485</td>\n",
       "      <td>508</td>\n",
       "      <td>493</td>\n",
       "      <td>487</td>\n",
       "      <td>478</td>\n",
       "      <td>472</td>\n",
       "      <td>504</td>\n",
       "      <td>476</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>486</td>\n",
       "      <td>480</td>\n",
       "      <td>535</td>\n",
       "      <td>534</td>\n",
       "      <td>514</td>\n",
       "      <td>452</td>\n",
       "      <td>484</td>\n",
       "      <td>495</td>\n",
       "      <td>548</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483</td>\n",
       "      <td>521</td>\n",
       "      <td>507</td>\n",
       "      <td>475</td>\n",
       "      <td>493</td>\n",
       "      <td>486</td>\n",
       "      <td>421</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>498</td>\n",
       "      <td>495</td>\n",
       "      <td>508</td>\n",
       "      <td>528</td>\n",
       "      <td>486</td>\n",
       "      <td>465</td>\n",
       "      <td>508</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>474</td>\n",
       "      <td>504</td>\n",
       "      <td>576</td>\n",
       "      <td>480</td>\n",
       "      <td>553</td>\n",
       "      <td>483</td>\n",
       "      <td>524</td>\n",
       "      <td>478</td>\n",
       "      <td>483</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>521</td>\n",
       "      <td>475</td>\n",
       "      <td>470</td>\n",
       "      <td>463</td>\n",
       "      <td>509</td>\n",
       "      <td>525</td>\n",
       "      <td>479</td>\n",
       "      <td>467</td>\n",
       "      <td>552</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>495</td>\n",
       "      <td>474</td>\n",
       "      <td>523</td>\n",
       "      <td>479</td>\n",
       "      <td>495</td>\n",
       "      <td>488</td>\n",
       "      <td>485</td>\n",
       "      <td>476</td>\n",
       "      <td>497</td>\n",
       "      <td>478</td>\n",
       "      <td>...</td>\n",
       "      <td>510</td>\n",
       "      <td>471</td>\n",
       "      <td>522</td>\n",
       "      <td>343</td>\n",
       "      <td>509</td>\n",
       "      <td>520</td>\n",
       "      <td>475</td>\n",
       "      <td>493</td>\n",
       "      <td>506</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  490  491  492  493   \n",
       "0  483  454  513  495  523  469  453  477  506  479  ...  455  480  543  259  \\\n",
       "1  485  508  493  487  478  472  504  476  479  475  ...  486  480  535  534   \n",
       "2  483  521  507  475  493  486  421  475  496  483  ...  491  476  498  495   \n",
       "3  474  504  576  480  553  483  524  478  483  483  ...  521  475  470  463   \n",
       "4  495  474  523  479  495  488  485  476  497  478  ...  510  471  522  343   \n",
       "\n",
       "   494  495  496  497  498  499  \n",
       "0  413  520  485  498  523  510  \n",
       "1  514  452  484  495  548  477  \n",
       "2  508  528  486  465  508  503  \n",
       "3  509  525  479  467  552  517  \n",
       "4  509  520  475  493  506  491  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artificial_test_x = pd.read_csv(\"datasets/artificial_valid.data\", sep = \" \", header=None).iloc[:, 0:500]\n",
    "artificial_test_x.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    artificial_train_x, \n",
    "    artificial_train_y,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - artificial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all methods\n",
    "def variance_threshold(X_train, t):\n",
    "    print(\"variance_threshold\")\n",
    "\n",
    "    sel = VarianceThreshold(threshold=t)\n",
    "    sel.fit_transform(X_train)\n",
    "    \n",
    "    return X_train.loc[:, sel.get_support()]\n",
    "\n",
    "\n",
    "def mean_absolute_deviance(X_train, t):\n",
    "    print(\"mean_absolute_deviance\")\n",
    "\n",
    "    mad = np.sum(np.abs(X_train - np.mean(X_train, axis=0)), axis=0) / X_train.shape[0]\n",
    "    return X_train.loc[:, mad > t] \n",
    "\n",
    "\n",
    "def high_correlation(X_train, t):\n",
    "    print(\"high_correlation\")\n",
    "    \n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > t)]\n",
    "    X_train.drop(to_drop, axis=1, inplace=True)\n",
    "    return X_train\n",
    "\n",
    "\n",
    "def information_gain(X_train, y_train, t):\n",
    "    print(\"information_gain\")\n",
    "\n",
    "    importance = mutual_info_classif(X_train, y_train)\n",
    "    return X_train.loc[:, importance > np.quantile(importance, t)]\n",
    "\n",
    "\n",
    "def fisher_score(X_train, y_train, t):\n",
    "    print(\"fisher_score\")\n",
    "    chi2_selector = SelectKBest(chi2, k=t)\n",
    "    chi2_selector.fit(X_train, y_train)\n",
    "\n",
    "    return X_train.loc[:, chi2_selector.get_support()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1\n",
    "def forward_feature_selection(X_train, y_train, t):\n",
    "    print(\"forward_features_selection\")\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=t)\n",
    "    sfs.fit(X_train, y_train)\n",
    "    return X_train.loc[:, sfs.get_support()]\n",
    "\n",
    "# method 2\n",
    "def recursive_feature_eliminator(X_train, y_train, t):\n",
    "    print(\"recursive_feature_eliminator\")\n",
    "\n",
    "    model = XGBClassifier()\n",
    "    rfe = RFE(estimator=model, n_features_to_select=t, step=1)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    return X_train.loc[:, rfe.get_support()]\n",
    "\n",
    "# method 3\n",
    "def select_from_model(X_train, y_train, t):\n",
    "    print(\"select_from_model\")\n",
    "\n",
    "    sfm = SelectFromModel(XGBClassifier(n_estimators=100), max_features=t)\n",
    "    sfm.fit(X_train, y_train)\n",
    "    return X_train.loc[:, sfm.get_support()]\n",
    "\n",
    "# method 4\n",
    "def logistic_regression_l1(X_train, y_train, t):\n",
    "    print(\"logistic_regression_l1\")\n",
    "\n",
    "    sfm = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear', max_iter=1000))\n",
    "    sfm.fit(X_train, y_train)\n",
    "    return X_train.iloc[:, sfm.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features initial: 500\n",
      "\n",
      "variance_threshold\n",
      "Features left: 500\n",
      "\n",
      "mean_absolute_deviance\n",
      "Features left: 477\n",
      "\n",
      "high_correlation\n",
      "Features left: 467\n",
      "\n",
      "information_gain\n",
      "Features left: 140\n",
      "\n",
      "fisher_score\n",
      "Features left: 5\n",
      "\n",
      "forward_features_selection\n",
      "Features left: 3\n",
      "\n",
      "Accuracy train: 0.9612\n",
      "Accuracy valid: 0.6899\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_method1(settings, X_train, y_train, X_valid, y_valid):\n",
    "    # Feature selection\n",
    "    print(f\"Features initial: {X_train.shape[1]}\\n\")\n",
    "\n",
    "    ## Methods to remove unnecessary features\n",
    "    X_train_t = variance_threshold(X_train, settings[\"variance_threshold\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = mean_absolute_deviance(X_train_t, settings[\"mean_absolute_deviance\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = high_correlation(X_train_t, settings[\"high_correlation\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    ## Methods to take important features\n",
    "    X_train_t = information_gain(X_train_t, y_train, settings[\"information_gain\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = fisher_score(X_train_t, y_train, settings[\"fisher_score\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = forward_feature_selection(X_train_t, y_train, settings[\"forward_feature_selection\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_valid_t = X_valid.loc[:, X_train_t.columns]\n",
    "\n",
    "    # Evaluation\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train_t, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train_t)\n",
    "    y_valid_pred = model.predict(X_valid_t)\n",
    "\n",
    "    print(f\"Accuracy train: {np.round(balanced_accuracy_score(y_train, y_train_pred), 4)}\")\n",
    "    print(f\"Accuracy valid: {np.round(balanced_accuracy_score(y_valid, y_valid_pred), 4)}\")\n",
    "    \n",
    "    return X_train_t, X_valid_t\n",
    "\n",
    "\n",
    "# smoke test\n",
    "settings = {\n",
    "    \"variance_threshold\": 0.1,\n",
    "    \"mean_absolute_deviance\": 2,\n",
    "    \"high_correlation\": 0.8,\n",
    "    \"information_gain\": 0.7,\n",
    "    \"fisher_score\": 5,\n",
    "    \"forward_feature_selection\": 3,\n",
    "}\n",
    "X_train_t, X_test_t = feature_selection_method1(\n",
    "    settings, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_valid,\n",
    "    y_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffss = list(range(5, 21, 2))\n",
    "iters = 3\n",
    "\n",
    "j = 0\n",
    "for ffs in ffss:\n",
    "    for i in range(iters):\n",
    "        settings = {\n",
    "            \"variance_threshold\": 0.1,\n",
    "            \"mean_absolute_deviance\": 2,\n",
    "            \"high_correlation\": 0.8,\n",
    "            \"information_gain\": 0.7,\n",
    "            \"fisher_score\": 30,\n",
    "            \"forward_feature_selection\": ffs,\n",
    "        }\n",
    "\n",
    "        X_train_t, X_test_t = feature_selection_method1(\n",
    "            settings, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_valid,\n",
    "            y_valid,\n",
    "        )\n",
    "\n",
    "        # accuracy on valid\n",
    "        xgb = XGBClassifier()\n",
    "        xgb.fit(X_train_t, y_train)\n",
    "\n",
    "\n",
    "        ba_valid = np.round(balanced_accuracy_score(y_valid, xgb.predict(X_test_t)), 2)\n",
    "\n",
    "        pd.DataFrame(xgb.predict_proba(X_test_t)).to_csv(f\"output/MACCHY_ddartificial_prediction_{j}_{ba_valid}.txt\")\n",
    "\n",
    "        np.savetxt(f\"output/MACCHY_ddartificial_features_{j}.txt\", X_train_t.columns.values.astype(int), fmt=\"%i\")\n",
    "\n",
    "        j += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - recursive feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features initial: 500\n",
      "\n",
      "variance_threshold\n",
      "Features left: 500\n",
      "\n",
      "mean_absolute_deviance\n",
      "Features left: 477\n",
      "\n",
      "high_correlation\n",
      "Features left: 467\n",
      "\n",
      "information_gain\n",
      "Features left: 140\n",
      "\n",
      "fisher_score\n",
      "Features left: 5\n",
      "\n",
      "recursive_feature_eliminator\n",
      "Features left: 3\n",
      "\n",
      "Accuracy train: 0.9719\n",
      "Accuracy valid: 0.6397\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_method2(settings, X_train, y_train, X_valid, y_valid):\n",
    "    # Feature selection\n",
    "    print(f\"Features initial: {X_train.shape[1]}\\n\")\n",
    "\n",
    "    ## Methods to remove unnecessary features\n",
    "    X_train_t = variance_threshold(X_train, settings[\"variance_threshold\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = mean_absolute_deviance(X_train_t, settings[\"mean_absolute_deviance\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = high_correlation(X_train_t, settings[\"high_correlation\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    ## Methods to take important features\n",
    "    X_train_t = information_gain(X_train_t, y_train, settings[\"information_gain\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = fisher_score(X_train_t, y_train, settings[\"fisher_score\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = recursive_feature_eliminator(X_train_t, y_train, settings[\"recursive_feature_eliminator\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_valid_t = X_valid.loc[:, X_train_t.columns]\n",
    "\n",
    "    # Evaluation\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train_t, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train_t)\n",
    "    y_valid_pred = model.predict(X_valid_t)\n",
    "\n",
    "    print(f\"Accuracy train: {np.round(balanced_accuracy_score(y_train, y_train_pred), 4)}\")\n",
    "    print(f\"Accuracy valid: {np.round(balanced_accuracy_score(y_valid, y_valid_pred), 4)}\")\n",
    "    \n",
    "    return X_train_t, X_valid_t\n",
    "\n",
    "\n",
    "# smoke test\n",
    "settings = {\n",
    "    \"variance_threshold\": 0.1,\n",
    "    \"mean_absolute_deviance\": 2,\n",
    "    \"high_correlation\": 0.8,\n",
    "    \"information_gain\": 0.7,\n",
    "    \"fisher_score\": 5,\n",
    "    \"recursive_feature_eliminator\": 3,\n",
    "}\n",
    "X_train_t, X_test_t = feature_selection_method2(\n",
    "    settings, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_valid,\n",
    "    y_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffss = list(range(5, 21, 2))\n",
    "iters = 3\n",
    "\n",
    "j = 0\n",
    "for ffs in ffss:\n",
    "    for i in range(iters):\n",
    "        settings = {\n",
    "            \"variance_threshold\": 0.1,\n",
    "            \"mean_absolute_deviance\": 2,\n",
    "            \"high_correlation\": 0.8,\n",
    "            \"information_gain\": 0.7,\n",
    "            \"fisher_score\": 30,\n",
    "            \"recursive_feature_eliminator\": ffs,\n",
    "        }\n",
    "\n",
    "        X_train_t, X_test_t = feature_selection_method2(\n",
    "            settings, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_valid,\n",
    "            y_valid,\n",
    "        )\n",
    "\n",
    "        # accuracy on valid\n",
    "        xgb = XGBClassifier()\n",
    "        xgb.fit(X_train_t, y_train)\n",
    "\n",
    "\n",
    "        ba_valid = np.round(balanced_accuracy_score(y_valid, xgb.predict(X_test_t)), 2)\n",
    "\n",
    "        pd.DataFrame(xgb.predict_proba(X_test_t)).to_csv(f\"output/MACCHY_ddartificial_prediction_{j}_{ba_valid}.txt\")\n",
    "\n",
    "        np.savetxt(f\"output/MACCHY_ddartificial_features_{j}.txt\", X_train_t.columns.values.astype(int), fmt=\"%i\")\n",
    "\n",
    "        j += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 - select most important from xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features initial: 500\n",
      "\n",
      "variance_threshold\n",
      "Features left: 500\n",
      "\n",
      "mean_absolute_deviance\n",
      "Features left: 477\n",
      "\n",
      "high_correlation\n",
      "Features left: 467\n",
      "\n",
      "information_gain\n",
      "Features left: 140\n",
      "\n",
      "fisher_score\n",
      "Features left: 5\n",
      "\n",
      "select_from_model\n",
      "Features left: 3\n",
      "\n",
      "Accuracy train: 0.9612\n",
      "Accuracy valid: 0.6899\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_method3(settings, X_train, y_train, X_valid, y_valid):\n",
    "    # Feature selection\n",
    "    print(f\"Features initial: {X_train.shape[1]}\\n\")\n",
    "\n",
    "    ## Methods to remove unnecessary features\n",
    "    X_train_t = variance_threshold(X_train, settings[\"variance_threshold\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = mean_absolute_deviance(X_train_t, settings[\"mean_absolute_deviance\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = high_correlation(X_train_t, settings[\"high_correlation\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    ## Methods to take important features\n",
    "    X_train_t = information_gain(X_train_t, y_train, settings[\"information_gain\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = fisher_score(X_train_t, y_train, settings[\"fisher_score\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = select_from_model(X_train_t, y_train, settings[\"select_from_model\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_valid_t = X_valid.loc[:, X_train_t.columns]\n",
    "\n",
    "    # Evaluation\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train_t, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train_t)\n",
    "    y_valid_pred = model.predict(X_valid_t)\n",
    "\n",
    "    print(f\"Accuracy train: {np.round(balanced_accuracy_score(y_train, y_train_pred), 4)}\")\n",
    "    print(f\"Accuracy valid: {np.round(balanced_accuracy_score(y_valid, y_valid_pred), 4)}\")\n",
    "    \n",
    "    return X_train_t, X_valid_t\n",
    "\n",
    "\n",
    "# smoke test\n",
    "settings = {\n",
    "    \"variance_threshold\": 0.1,\n",
    "    \"mean_absolute_deviance\": 2,\n",
    "    \"high_correlation\": 0.8,\n",
    "    \"information_gain\": 0.7,\n",
    "    \"fisher_score\": 5,\n",
    "    \"select_from_model\": 3,\n",
    "}\n",
    "X_train_t, X_test_t = feature_selection_method3(\n",
    "    settings, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_valid,\n",
    "    y_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffss = list(range(5, 21, 2))\n",
    "iters = 3\n",
    "\n",
    "j = 0\n",
    "for ffs in ffss:\n",
    "    for i in range(iters):\n",
    "        settings = {\n",
    "            \"variance_threshold\": 0.1,\n",
    "            \"mean_absolute_deviance\": 2,\n",
    "            \"high_correlation\": 0.8,\n",
    "            \"information_gain\": 0.7,\n",
    "            \"fisher_score\": 30,\n",
    "            \"select_from_model\": ffs,\n",
    "        }\n",
    "\n",
    "        X_train_t, X_test_t = feature_selection_method3(\n",
    "            settings, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_valid,\n",
    "            y_valid,\n",
    "        )\n",
    "\n",
    "        # accuracy on valid\n",
    "        xgb = XGBClassifier()\n",
    "        xgb.fit(X_train_t, y_train)\n",
    "\n",
    "\n",
    "        ba_valid = np.round(balanced_accuracy_score(y_valid, xgb.predict(X_test_t)), 2)\n",
    "\n",
    "        pd.DataFrame(xgb.predict_proba(X_test_t)).to_csv(f\"output/MACCHY_ddartificial_prediction_{j}_{ba_valid}.txt\")\n",
    "\n",
    "        np.savetxt(f\"output/MACCHY_ddartificial_features_{j}.txt\", X_train_t.columns.values.astype(int), fmt=\"%i\")\n",
    "\n",
    "        j += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4 - logistic regression with L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features initial: 500\n",
      "\n",
      "variance_threshold\n",
      "Features left: 500\n",
      "\n",
      "mean_absolute_deviance\n",
      "Features left: 477\n",
      "\n",
      "high_correlation\n",
      "Features left: 467\n",
      "\n",
      "information_gain\n",
      "Features left: 140\n",
      "\n",
      "fisher_score\n",
      "Features left: 5\n",
      "\n",
      "logistic_regression_l1\n",
      "Features left: 5\n",
      "\n",
      "Accuracy train: 0.9981\n",
      "Accuracy valid: 0.7878\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_method4(settings, X_train, y_train, X_valid, y_valid):\n",
    "    # Feature selection\n",
    "    print(f\"Features initial: {X_train.shape[1]}\\n\")\n",
    "\n",
    "    ## Methods to remove unnecessary features\n",
    "    X_train_t = variance_threshold(X_train, settings[\"variance_threshold\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = mean_absolute_deviance(X_train_t, settings[\"mean_absolute_deviance\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = high_correlation(X_train_t, settings[\"high_correlation\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    ## Methods to take important features\n",
    "    X_train_t = information_gain(X_train_t, y_train, settings[\"information_gain\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = fisher_score(X_train_t, y_train, settings[\"fisher_score\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_train_t = logistic_regression_l1(X_train_t, y_train, settings[\"logistic_regression_l1\"])\n",
    "    print(f\"Features left: {X_train_t.shape[1]}\\n\")\n",
    "\n",
    "    X_valid_t = X_valid.loc[:, X_train_t.columns]\n",
    "\n",
    "    # Evaluation\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train_t, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train_t)\n",
    "    y_valid_pred = model.predict(X_valid_t)\n",
    "\n",
    "    print(f\"Accuracy train: {np.round(balanced_accuracy_score(y_train, y_train_pred), 4)}\")\n",
    "    print(f\"Accuracy valid: {np.round(balanced_accuracy_score(y_valid, y_valid_pred), 4)}\")\n",
    "    \n",
    "    return X_train_t, X_valid_t\n",
    "\n",
    "\n",
    "# smoke test\n",
    "settings = {\n",
    "    \"variance_threshold\": 0.1,\n",
    "    \"mean_absolute_deviance\": 2,\n",
    "    \"high_correlation\": 0.8,\n",
    "    \"information_gain\": 0.7,\n",
    "    \"fisher_score\": 5,\n",
    "    \"logistic_regression_l1\": 3,\n",
    "}\n",
    "X_train_t, X_test_t = feature_selection_method4(\n",
    "    settings, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_valid,\n",
    "    y_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffss = list(range(5, 21, 2))\n",
    "iters = 3\n",
    "\n",
    "j = 0\n",
    "for ffs in ffss:\n",
    "    for i in range(iters):\n",
    "        settings = {\n",
    "            \"variance_threshold\": 0.1,\n",
    "            \"mean_absolute_deviance\": 2,\n",
    "            \"high_correlation\": 0.8,\n",
    "            \"information_gain\": 0.7,\n",
    "            \"fisher_score\": 30,\n",
    "            \"logistic_regression_l1\": ffs,\n",
    "        }\n",
    "\n",
    "        X_train_t, X_test_t = feature_selection_method4(\n",
    "            settings, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_valid,\n",
    "            y_valid,\n",
    "        )\n",
    "\n",
    "        # accuracy on valid\n",
    "        xgb = XGBClassifier()\n",
    "        xgb.fit(X_train_t, y_train)\n",
    "\n",
    "\n",
    "        ba_valid = np.round(balanced_accuracy_score(y_valid, xgb.predict(X_test_t)), 2)\n",
    "\n",
    "        pd.DataFrame(xgb.predict_proba(X_test_t)).to_csv(f\"output/MACCHY_ddartificial_prediction_{j}_{ba_valid}.txt\")\n",
    "\n",
    "        np.savetxt(f\"output/MACCHY_ddartificial_features_{j}.txt\", X_train_t.columns.values.astype(int), fmt=\"%i\")\n",
    "\n",
    "        j += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sms_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_csv(\"datasets/sms_train.csv\")\n",
    "sms_train_x = df_tmp.loc[:, \"message\"]\n",
    "sms_train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_train_y = df_tmp.loc[:, \"label\"]\n",
    "sms_train_y.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sms_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_csv(\"datasets/sms_test.csv\")\n",
    "sms_test_x = df_tmp.loc[:, \"message\"]\n",
    "sms_test_x.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
